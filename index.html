<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Placeholder Project Title</title>

  <!-- Fonts and Styles -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css">
</head>
<body>

<!-- Navbar -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="#">
      <span class="icon">
        <i class="fas fa-home"></i>
      </span>
    </a>
  </div>
</nav>

<!-- Hero Title -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">Multi-Modal Fine-Tuning for Robot-Assisted Dressing with Arm Motions</h1>
      <p class="subtitle is-5">
        Anonymous Authors
      </p>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <h2 class="title is-3 has-text-centered">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robot-assisted dressing has the potential to significantly improve the lives of individuals with mobility impairments. To ensure an effective and comfortable dressing experience, the robot must be able to handle challenging deformable garments, apply appropriate forces, and adapt to limb movements throughout the dressing process. Prior work often makes simplifying assumptions—such as static human limbs during dressing—which limits real-world applicability. In this work, we develop a robot-assisted dressing system capable of handling partial observations with visual occlusions, as well as robustly adapting to arm motions during the dressing process. Given a policy trained in simulation with partial observations, we propose a method to fine-tune it in the real world using a small amount of data and multi-modal feedback from vision and force sensing, to further improve the policy’s adaptability to arm motions and enhance safety. We evaluate our method in simulation with simplified articulated human meshes and in a real world human study with 12 participants across 264 dressing trials. Our policy successfully dresses two long-sleeve everyday garments onto the participants while being adaptive to various kinds of arm motions, and greatly outperforms prior baselines in terms of task completion and user feedback.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Overview Video -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <h2 class="title is-3 has-text-centered">Overview Video</h2>
        <div class="content has-text-centered">
          <video width="100%" controls>
            <source src="static/videos/corl_video_final.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Real-World Human Study Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Real-World Human Study</h2>

    <!-- Subsection -->
    <h3 class="title is-3">Generalization to Different Arm Motions</h3>

    <!-- Group 1 -->
    <h4 class="title is-4">Motion: Lower Arm</h4>
    <div id="group1" class="columns is-centered">
      <div class="column is-one-third">
        <video width="100%" muted playsinline controls>
          <source src="static/videos/user_study/ours/study_blurred_user5_m2.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column is-one-third">
        <video width="100%" muted playsinline controls>
          <source src="static/videos/user_study/ours/study_blurred_user8_m2.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column is-one-third">
        <video width="100%" muted playsinline controls>
          <source src="static/videos/user_study/ours/study_blurred_user7_m2.mp4" type="video/mp4">
        </video>
      </div>
    </div>

  </div>
</section>

<!-- Footer -->
<footer class="footer">
  <div class="content has-text-centered">
    <p>
      Template adapted from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies project website</a>. You are free to reuse and customize this template.
    </p>
  </div>
</footer>

<!-- Autoplay on Scroll Script -->
<script>
  function setupVideoAutoplay(groupId) {
    const group = document.getElementById(groupId);
    const videos = group.querySelectorAll('video');
    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          videos.forEach(video => {
            video.play().catch(e => {
              console.log('Autoplay blocked for', video);
            });
          });
        } else {
          videos.forEach(video => video.pause());
        }
      });
    }, { threshold: 0.5 });

    observer.observe(group);
  }

  setupVideoAutoplay('group1');
</script>

</body>
</html>
